{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 61542,
          "databundleVersionId": 6888007,
          "sourceType": "competition"
        },
        {
          "sourceId": 6847931,
          "sourceType": "datasetVersion",
          "datasetId": 3936750
        },
        {
          "sourceId": 6867914,
          "sourceType": "datasetVersion",
          "datasetId": 3946973
        },
        {
          "sourceId": 6868189,
          "sourceType": "datasetVersion",
          "datasetId": 3937441
        },
        {
          "sourceId": 6888403,
          "sourceType": "datasetVersion",
          "datasetId": 3955358
        },
        {
          "sourceId": 6890527,
          "sourceType": "datasetVersion",
          "datasetId": 3942644
        },
        {
          "sourceId": 6920799,
          "sourceType": "datasetVersion",
          "datasetId": 3973977
        },
        {
          "sourceId": 6977472,
          "sourceType": "datasetVersion",
          "datasetId": 4005256
        },
        {
          "sourceId": 7017419,
          "sourceType": "datasetVersion",
          "datasetId": 3937250
        },
        {
          "sourceId": 7060310,
          "sourceType": "datasetVersion",
          "datasetId": 3944051
        },
        {
          "sourceId": 7149898,
          "sourceType": "datasetVersion",
          "datasetId": 4123812
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Install Libraries"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "AoHXAmEd7uKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-core --upgrade\n",
        "!pip install -q keras-nlp --upgrade\n",
        "!pip install --upgrade -q wandb git+https://github.com/soumik12345/wandb-addons"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-08T09:27:16.841069Z",
          "iopub.execute_input": "2023-12-08T09:27:16.842051Z",
          "iopub.status.idle": "2023-12-08T09:28:35.698848Z",
          "shell.execute_reply.started": "2023-12-08T09:27:16.842013Z",
          "shell.execute_reply": "2023-12-08T09:28:35.697091Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x4lpMuYc7uKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # \"jax\" or \"tensorflow\" or \"torch\"\n",
        "# os.environ[\"WANDB_SILENT\"] = \"false\" # for wandb\n",
        "\n",
        "import keras_nlp\n",
        "import keras_core as keras\n",
        "import keras_core.backend as K\n",
        "\n",
        "\n",
        "import torch\n",
        "# import jax\n",
        "import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "cmap = mpl.cm.get_cmap('coolwarm')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:35.701555Z",
          "iopub.execute_input": "2023-12-08T09:28:35.702009Z",
          "iopub.status.idle": "2023-12-08T09:28:56.666787Z",
          "shell.execute_reply.started": "2023-12-08T09:28:35.701963Z",
          "shell.execute_reply": "2023-12-08T09:28:56.662402Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-kl8_7547uKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow:\", tf.__version__)\n",
        "# print(\"JAX:\", jax.__version__)\n",
        "print(\"Keras:\", keras.__version__)\n",
        "print(\"KerasNLP:\", keras_nlp.__version__)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.668406Z",
          "iopub.status.idle": "2023-12-08T09:28:56.669541Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.668890Z",
          "shell.execute_reply": "2023-12-08T09:28:56.668923Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s5_p7toz7uKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "2DURjVNn7uKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    verbose = 0  # Verbosity\n",
        "\n",
        "    wandb = True  # Weights & Biases logging\n",
        "    competition = 'llm-detect-ai-generated-text'  # Competition name\n",
        "    _wandb_kernel = 'awsaf49'  # WandB kernel\n",
        "    comment = 'DebertaV3-MaxSeq_200-ext_s-torch'  # Comment description\n",
        "\n",
        "    preset = \"deberta_v3_base_en\"  # Name of pretrained models\n",
        "    sequence_length = 200  # Input sequence length\n",
        "\n",
        "    device = 'TPU'  # Device\n",
        "\n",
        "    seed = 42  # Random seed\n",
        "\n",
        "    num_folds = 5  # Total folds\n",
        "    selected_folds = [1]  # Folds to train on\n",
        "\n",
        "    epochs = 2 # Training epochs\n",
        "    batch_size = 3  # Batch size\n",
        "    drop_remainder = True  # Drop incomplete batches\n",
        "    cache = True # Caches data after one iteration, use only with `TPU` to avoid OOM\n",
        "\n",
        "    scheduler = 'cosine'  # Learning rate scheduler\n",
        "\n",
        "    class_names = [\"real\", \"fake\"]  # Class names [A, B, C, D, E]\n",
        "    num_classes = len(class_names)  # Number of classes\n",
        "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
        "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
        "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.671460Z",
          "iopub.status.idle": "2023-12-08T09:28:56.672076Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.671782Z",
          "shell.execute_reply": "2023-12-08T09:28:56.671813Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VT0qzOOV7uKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.set_random_seed(CFG.seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.673908Z",
          "iopub.status.idle": "2023-12-08T09:28:56.674333Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.674135Z",
          "shell.execute_reply": "2023-12-08T09:28:56.674156Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lmjr3IFW7uKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use GPU or TPU to accelerate  "
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ty74xODY7uKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    \"Detect and intializes GPU/TPU automatically\"\n",
        "    try:\n",
        "        # Connect to TPU\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "        # Set TPU strategy\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\n",
        "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
        "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
        "        device=CFG.device\n",
        "    except:\n",
        "        # If TPU is not available, detect GPUs\n",
        "        gpus = tf.config.list_logical_devices('GPU')\n",
        "        ngpu = len(gpus)\n",
        "         # Check number of GPUs\n",
        "        if ngpu:\n",
        "            # Set GPU strategy\n",
        "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
        "            # Print GPU details\n",
        "            print(\"> Running on GPU\", end=' | ')\n",
        "            print(\"Num of GPUs: \", ngpu)\n",
        "            device='GPU'\n",
        "        else:\n",
        "            # If no GPUs are available, use CPU\n",
        "            print(\"> Running on CPU\")\n",
        "            strategy = tf.distribute.get_strategy()\n",
        "            device='CPU'\n",
        "    return strategy, device"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.676043Z",
          "iopub.status.idle": "2023-12-08T09:28:56.676504Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.676271Z",
          "shell.execute_reply": "2023-12-08T09:28:56.676292Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y82E49pJ7uKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GPU/TPU/TPU-VM\n",
        "strategy, CFG.device = get_device()\n",
        "CFG.replicas = strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.677683Z",
          "iopub.status.idle": "2023-12-08T09:28:56.678059Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.677872Z",
          "shell.execute_reply": "2023-12-08T09:28:56.677889Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bWjVgoZT7uKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "MY9mU2N27uKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.679276Z",
          "iopub.status.idle": "2023-12-08T09:28:56.679712Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.679500Z",
          "shell.execute_reply": "2023-12-08T09:28:56.679528Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E1cI56_v7uKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.681730Z",
          "iopub.status.idle": "2023-12-08T09:28:56.682172Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.681960Z",
          "shell.execute_reply": "2023-12-08T09:28:56.681987Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mc5L3Cms7uKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "train_dataset = read_csv('/data/teset_data.csv')[['text', 'label']].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uuHc-kbYBhBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.683239Z",
          "iopub.status.idle": "2023-12-08T09:28:56.683701Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.683469Z",
          "shell.execute_reply": "2023-12-08T09:28:56.683519Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4dKQjnF37uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.text = train_dataset.text.str.replace('\\n', ' ')\n",
        "class_0 = train_dataset[train_dataset['label'] == 0]\n",
        "class_1 = train_dataset[train_dataset['label'] == 1]\n",
        "\n",
        "# 确定两个类别的样本数量\n",
        "num_class_0 = len(class_0)\n",
        "num_class_1 = len(class_1)\n",
        "\n",
        "# 计算较小的样本数量\n",
        "min_num = min(num_class_0, num_class_1)\n",
        "\n",
        "# 对样本较多的类别进行随机抽样\n",
        "if num_class_0 > min_num:\n",
        "    class_0 = class_0.sample(n=min_num, random_state=42)  # random_state 确保结果的可复现性\n",
        "elif num_class_1 > min_num:\n",
        "    class_1 = class_1.sample(n=min_num, random_state=42)\n",
        "\n",
        "# 合并数据集\n",
        "balanced_train_dataset = pd.concat([class_0, class_1])\n",
        "\n",
        "# 如果需要，可以打乱数据集的顺序\n",
        "balanced_train_dataset = balanced_train_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_dataset.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.684768Z",
          "iopub.status.idle": "2023-12-08T09:28:56.685166Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.684974Z",
          "shell.execute_reply": "2023-12-08T09:28:56.684993Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HvD6w9wq7uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load external data\n",
        "train_dataset = balanced_train_dataset\n",
        "\n",
        "train_dataset['name'] = train_dataset.label.map(CFG.label2name)\n",
        "\n",
        "# Display information about the external data\n",
        "print(\"# External Data: {:,}\".format(len(train_dataset)))\n",
        "print(\"# Sample:\")\n",
        "train_dataset.head(2)\n",
        "\n",
        "# Show distribution of answers using a bar plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "train_dataset.name.value_counts().plot.bar(color=[cmap(0.0), cmap(0.65)])\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Answer distribution for External Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.686419Z",
          "iopub.status.idle": "2023-12-08T09:28:56.686878Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.686682Z",
          "shell.execute_reply": "2023-12-08T09:28:56.686703Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "elsUcuYP7uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = train_dataset\n",
        "df['source'] = 'default_score_value'  # 将'score'列的所有值设置为默认字符串\n",
        "df['id'] = 'default_id_value'\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.688712Z",
          "iopub.status.idle": "2023-12-08T09:28:56.689118Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.688920Z",
          "shell.execute_reply": "2023-12-08T09:28:56.688939Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PERechoZ7uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold  # Import package\n",
        "\n",
        "skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=CFG.seed)  # Initialize K-Fold\n",
        "\n",
        "df = df.reset_index(drop=True)  # Reset dataframe index\n",
        "\n",
        "df['stratify'] = df.label.astype(str)+df.source.astype(str)\n",
        "\n",
        "df[\"fold\"] = -1  # New 'fold' column\n",
        "\n",
        "# Assign folds using StratifiedKFold\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['stratify'])):\n",
        "    df.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "# Display label distribution for each fold\n",
        "df.groupby([\"fold\", \"name\", \"source\"]).size()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.690405Z",
          "iopub.status.idle": "2023-12-08T09:28:56.690860Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.690661Z",
          "shell.execute_reply": "2023-12-08T09:28:56.690681Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pINK_yNW7uKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5wGtcGSb7uKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
        "    preset=CFG.preset, # Name of the model\n",
        "    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.692638Z",
          "iopub.status.idle": "2023-12-08T09:28:56.693063Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.692862Z",
          "shell.execute_reply": "2023-12-08T09:28:56.692883Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "acN1MirC7uKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = preprocessor(df.text.iloc[0])  # Process text for the first row\n",
        "\n",
        "# Display the shape of each processed output\n",
        "for k, v in inp.items():\n",
        "    print(k, \":\", v.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.694388Z",
          "iopub.status.idle": "2023-12-08T09:28:56.694863Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.694658Z",
          "shell.execute_reply": "2023-12-08T09:28:56.694679Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nC7_dbIF7uKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_fn(text, label=None):\n",
        "    text = preprocessor(text)  # Preprocess text\n",
        "    return (text, label) if label is not None else text  # Return processed text and label if available"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.696889Z",
          "iopub.status.idle": "2023-12-08T09:28:56.697284Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.697094Z",
          "shell.execute_reply": "2023-12-08T09:28:56.697112Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WSn8Uhnr7uKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "wuGnAVxk7uKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(texts, labels=None, batch_size=32,\n",
        "                  cache=False, drop_remainder=True,\n",
        "                  repeat=False, shuffle=1024):\n",
        "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
        "    slices = (texts,) if labels is None else (texts, labels)  # Create slices\n",
        "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
        "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
        "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
        "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
        "    opt = tf.data.Options()  # Create dataset options\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
        "        opt.experimental_deterministic = False\n",
        "    ds = ds.with_options(opt)  # Set dataset options\n",
        "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
        "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
        "    return ds  # Return the built dataset"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.698674Z",
          "iopub.status.idle": "2023-12-08T09:28:56.699069Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.698881Z",
          "shell.execute_reply": "2023-12-08T09:28:56.698899Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NjDNwjqz7uKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets(fold):\n",
        "    train_df = df[df.fold!=fold].sample(frac=1)  # Get training fold data\n",
        "\n",
        "    train_texts = train_df.text.tolist()  # Extract training texts\n",
        "    train_labels = train_df.label.tolist()  # Extract training labels\n",
        "\n",
        "    # Build training dataset\n",
        "    train_ds = build_dataset(train_texts, train_labels,\n",
        "                             batch_size=CFG.batch_size*CFG.replicas, cache=CFG.cache,\n",
        "                             shuffle=True, drop_remainder=True, repeat=True)\n",
        "\n",
        "    valid_df = df[df.fold==fold].sample(frac=1)  # Get validation fold data\n",
        "    valid_texts = valid_df.text.tolist()  # Extract validation texts\n",
        "    valid_labels = valid_df.label.tolist()  # Extract validation labels\n",
        "\n",
        "    # Build validation dataset\n",
        "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
        "                             batch_size=min(CFG.batch_size*CFG.replicas, len(valid_df)), cache=CFG.cache,\n",
        "                             shuffle=False, drop_remainder=True, repeat=False)\n",
        "\n",
        "    return (train_ds, train_df), (valid_ds, valid_df)  # Return datasets and dataframes"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.700712Z",
          "iopub.status.idle": "2023-12-08T09:28:56.701091Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.700912Z",
          "shell.execute_reply": "2023-12-08T09:28:56.700929Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ixDEd7217uKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wandb"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FyxUuzaC7uKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb  # Import wandb library for experiment tracking\n",
        "import wandb_addons # Additional wandb utilities\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient  # Import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()  # Create secrets client instance\n",
        "    api_key = user_secrets.get_secret(\"WANDB\")  # Get API key from Kaggle secrets\n",
        "    wandb.login(key=api_key)  # Login to wandb with the API key\n",
        "    anonymous = None  # Set anonymous mode to None\n",
        "except:\n",
        "    anonymous = 'must'  # Set anonymous mode to 'must'\n",
        "    wandb.login(anonymous=anonymous, relogin=True)  # Login to wandb anonymously and relogin if needed"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.702403Z",
          "iopub.status.idle": "2023-12-08T09:28:56.702824Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.702636Z",
          "shell.execute_reply": "2023-12-08T09:28:56.702655Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wTiifwon7uKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from wandb_addons.keras import WandbMetricsLogger\n",
        "# from wandb_addons.keras import WandbModelCheckpoint\n",
        "\n",
        "\n",
        "# Initializes the W&B run with a config file and W&B run settings.\n",
        "def wandb_init(fold):\n",
        "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}  # Create config dictionary\n",
        "    config.update({\"fold\": int(fold)})  # Add fold to config\n",
        "    run = wandb.init(project=\"llm-fake-text\",\n",
        "                     name=f\"fold-{fold}|max_seq-{CFG.sequence_length}|model-{CFG.preset}\",\n",
        "                     config=config,\n",
        "                     group=CFG.comment,\n",
        "                     save_code=True)\n",
        "    return run\n",
        "\n",
        "# Log best result for error analysis\n",
        "def log_wandb():\n",
        "    wandb.log({'best_auc': best_auc, 'best_loss': best_loss, 'best_epoch': best_epoch})\n",
        "\n",
        "# Fetch W&B callbacks\n",
        "def get_wb_callbacks(fold):\n",
        "#     wb_ckpt = WandbModelCheckpoint(f'fold{fold}.keras',\n",
        "#                                    monitor='val_auc',\n",
        "#                                    save_best_only=True,\n",
        "#                                    save_weights_only=False,\n",
        "#                                    mode='max')\n",
        "    wb_metr = wandb.keras.WandbMetricsLogger()\n",
        "    return [wb_metr]  # Return WandB callbacks\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.704338Z",
          "iopub.status.idle": "2023-12-08T09:28:56.704757Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.704562Z",
          "shell.execute_reply": "2023-12-08T09:28:56.704582Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QDIj_REK7uKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR Schedule"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "V0YHSeWK7uKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
        "    lr_start, lr_max, lr_min = 0.6e-6, 0.5e-6 * batch_size, 0.3e-6\n",
        "    lr_ramp_ep, lr_sus_ep, lr_decay = 1, 0, 0.75\n",
        "\n",
        "    def lrfn(epoch):  # Learning rate update function\n",
        "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
        "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
        "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        return lr\n",
        "\n",
        "    if plot:  # Plot lr curve if plot is True\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
        "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
        "        plt.title('LR Scheduler')\n",
        "        plt.show()\n",
        "\n",
        "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.706376Z",
          "iopub.status.idle": "2023-12-08T09:28:56.706796Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.706604Z",
          "shell.execute_reply": "2023-12-08T09:28:56.706623Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QitUXCH57uKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_=get_lr_callback(CFG.batch_size*CFG.replicas, plot=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.708120Z",
          "iopub.status.idle": "2023-12-08T09:28:56.708552Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.708315Z",
          "shell.execute_reply": "2023-12-08T09:28:56.708332Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g-dvfOEA7uKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks(fold):\n",
        "    callbacks = []\n",
        "    lr_cb = get_lr_callback(CFG.batch_size*CFG.replicas)  # Get lr callback\n",
        "    ckpt_cb = keras.callbacks.ModelCheckpoint(f'fold{fold}.keras',\n",
        "                                              monitor='val_auc',\n",
        "                                              save_best_only=True,\n",
        "                                              save_weights_only=False,\n",
        "                                              mode='max')  # Get Model checkpoint callback\n",
        "    callbacks.extend([lr_cb, ckpt_cb])  # Add lr and checkpoint callbacks\n",
        "\n",
        "    if CFG.wandb:  # If WandB is enabled\n",
        "        wb_cbs = get_wb_callbacks(fold)  # Get WandB callbacks\n",
        "        callbacks.extend(wb_cbs)\n",
        "\n",
        "    return callbacks  # Return the list of callbacks"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.710455Z",
          "iopub.status.idle": "2023-12-08T09:28:56.710902Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.710705Z",
          "shell.execute_reply": "2023-12-08T09:28:56.710725Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gGb7OU_N7uKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model\n",
        "DebertaV3\n"
      ],
      "metadata": {
        "id": "gOo6qmJDC2SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    # Create a DebertaV3Classifier model\n",
        "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
        "        CFG.preset,\n",
        "        preprocessor=None,\n",
        "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
        "    )\n",
        "    inputs = classifier.input\n",
        "    logits = classifier(inputs)\n",
        "\n",
        "    # Compute final output\n",
        "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model with optimizer, loss, and metrics\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.AdamW(5e-6),\n",
        "        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.02),\n",
        "        metrics=[\n",
        "            keras.metrics.AUC(name=\"auc\"),\n",
        "        ],\n",
        "        jit_compile=True\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.712400Z",
          "iopub.status.idle": "2023-12-08T09:28:56.712886Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.712684Z",
          "shell.execute_reply": "2023-12-08T09:28:56.712707Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UUk00L8N7uKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with strategy.scope\n",
        "model = build_model()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.714234Z",
          "iopub.status.idle": "2023-12-08T09:28:56.714675Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.714437Z",
          "shell.execute_reply": "2023-12-08T09:28:56.714464Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xZb-sV957uKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.716333Z",
          "iopub.status.idle": "2023-12-08T09:28:56.716786Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.716578Z",
          "shell.execute_reply": "2023-12-08T09:28:56.716599Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3IglOfYT7uKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.718099Z",
          "iopub.status.idle": "2023-12-08T09:28:56.718559Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.718306Z",
          "shell.execute_reply": "2023-12-08T09:28:56.718325Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wFeVrt9T7uKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YAsckyos7uKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in CFG.selected_folds:\n",
        "    # Initialize Weights and Biases if enabled\n",
        "    if CFG.wandb:\n",
        "        run = wandb_init(fold)\n",
        "\n",
        "    # Get train and validation datasets\n",
        "    (train_ds, train_df), (valid_ds, valid_df) = get_datasets(fold)\n",
        "\n",
        "    # Get callback functions for training\n",
        "    callbacks = get_callbacks(fold)\n",
        "\n",
        "    # Print training information\n",
        "    print('#' * 50)\n",
        "    print(f'\\tFold: {fold + 1} | Model: {CFG.preset}\\n\\tBatch Size: {CFG.batch_size * CFG.replicas} | Scheduler: {CFG.scheduler}')\n",
        "    print(f'\\tNum Train: {len(train_df)} | Num Valid: {len(valid_df)}')\n",
        "    print('#' * 50)\n",
        "\n",
        "    # Clear TensorFlow session and build the model within the strategy scope\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "\n",
        "    # Start training the model\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=CFG.epochs,\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=callbacks,\n",
        "        steps_per_epoch=int(len(train_df) / CFG.batch_size / CFG.replicas),\n",
        "    )\n",
        "\n",
        "    # Find the epoch with the best validation accuracy\n",
        "    best_epoch = np.argmax(model.history.history['val_auc'])\n",
        "    best_auc = model.history.history['val_auc'][best_epoch]\n",
        "    best_loss = model.history.history['val_loss'][best_epoch]\n",
        "\n",
        "    # Print and display best results\n",
        "    print(f'\\n{\"=\" * 17} FOLD {fold} RESULTS {\"=\" * 17}')\n",
        "    print(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST AUC   : {best_auc:.3f}\\n>>>> BEST Epoch : {best_epoch}')\n",
        "    print('=' * 50)\n",
        "\n",
        "    # Log best result on Weights and Biases (wandb) if enabled\n",
        "    if CFG.wandb:\n",
        "        log_wandb()  # Log results\n",
        "        wandb.run.finish()  # Finish the run\n",
        "#         display(ipd.IFrame(run.url, width=1080, height=720)) # show wandb dashboard\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.719748Z",
          "iopub.status.idle": "2023-12-08T09:28:56.720113Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.719937Z",
          "shell.execute_reply": "2023-12-08T09:28:56.719954Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AdmkxffG7uKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "pGzqH4GPDDM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# 加载另一个测试数据集\n",
        "another_test_data_path = \"/content/real_data/teset_data.csv\"\n",
        "another_test_df = pd.read_csv(another_test_data_path)\n",
        "\n",
        "# 将测试数据转换为列表\n",
        "another_test_texts = another_test_df[\"text\"].tolist()\n",
        "another_test_labels = another_test_df[\"label\"].tolist()  # 假设测试数据集包含真实标签\n",
        "\n",
        "# 使用之前定义的build_dataset函数构建测试数据集\n",
        "another_test_ds = build_dataset(another_test_texts, batch_size=CFG.batch_size*CFG.replicas, cache=False, shuffle=False, drop_remainder=False, repeat=False)\n",
        "\n",
        "# 使用训练好的模型进行预测\n",
        "another_predictions = model.predict(another_test_ds)\n",
        "\n",
        "# 如果模型输出是sigmoid激活，则predictions已经是概率\n",
        "# 如果模型输出是logits，则需要转换为概率，例如使用sigmoid函数\n",
        "# another_predictions = tf.sigmoid(another_predictions).numpy().flatten()\n",
        "\n",
        "# 将预测结果转换为二进制标签\n",
        "binary_predictions = [1 if p > 0.5 else 0 for p in another_predictions.flatten()]\n",
        "\n",
        "# 计算准确率、F1分数和AUC值\n",
        "accuracy = accuracy_score(another_test_labels, binary_predictions)\n",
        "\n",
        "\n",
        "# 打印指标\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.721467Z",
          "iopub.status.idle": "2023-12-08T09:28:56.721860Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.721682Z",
          "shell.execute_reply": "2023-12-08T09:28:56.721700Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vXkuJs3W7uKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# 加载测试数据集\n",
        "test_data_path = \"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n",
        "test_df = pd.read_csv(test_data_path)\n",
        "\n",
        "# 将测试数据转换为列表\n",
        "test_texts = test_df[\"text\"].tolist()\n",
        "\n",
        "# 使用之前定义的build_dataset函数构建测试数据集\n",
        "# 假设 CFG.batch_size 和 CFG.replicas 已经定义\n",
        "test_ds = build_dataset(test_texts, batch_size=CFG.batch_size*CFG.replicas, cache=False, shuffle=False, drop_remainder=False, repeat=False)\n",
        "\n",
        "# 使用训练好的模型进行预测\n",
        "# 假设模型已经加载为 model\n",
        "predictions = model.predict(test_ds)\n",
        "\n",
        "# 将预测结果转换为概率\n",
        "# 如果模型输出是sigmoid激活，则predictions已经是概率\n",
        "# 如果模型输出是logits，则需要转换为概率，例如使用sigmoid函数\n",
        "# predictions = tf.sigmoid(predictions).numpy().flatten()\n",
        "\n",
        "# 创建一个新的DataFrame来存储结果\n",
        "results_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'generated': predictions.flatten()\n",
        "})\n",
        "\n",
        "# 保存结果到CSV文件\n",
        "output_csv_path = 'submission.csv'\n",
        "results_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Results saved to {output_csv_path}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.723158Z",
          "iopub.status.idle": "2023-12-08T09:28:56.723543Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.723334Z",
          "shell.execute_reply": "2023-12-08T09:28:56.723351Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gN8buJvo7uKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.725117Z",
          "iopub.status.idle": "2023-12-08T09:28:56.725531Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.725301Z",
          "shell.execute_reply": "2023-12-08T09:28:56.725316Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p1KL2Xvx7uKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✍️ | Reference\n",
        "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
        "* [Keras NLP](https://keras.io/api/keras_nlp/)\n",
        "* [Triple Stratified KFold with TFRecords](https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords) by @cdeotte"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "osJIXAmb7uKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /kaggle/working/wandb"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-12-08T09:28:56.726886Z",
          "iopub.status.idle": "2023-12-08T09:28:56.727304Z",
          "shell.execute_reply.started": "2023-12-08T09:28:56.727098Z",
          "shell.execute_reply": "2023-12-08T09:28:56.727117Z"
        },
        "trusted": true,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qab1XOuP7uKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
