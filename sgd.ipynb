{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "train_dataset = read_csv('data/train_data.csv')[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:01.450852Z",
     "iopub.status.busy": "2023-12-08T20:54:01.450355Z",
     "iopub.status.idle": "2023-12-08T20:54:12.347301Z",
     "shell.execute_reply": "2023-12-08T20:54:12.346170Z",
     "shell.execute_reply.started": "2023-12-08T20:54:01.450806Z"
    }
   },
   "outputs": [],
   "source": [
    "# curated_dataset = read_csv('../input/daigt-proper-train-dataset/train_drcat_01.csv')[['text', 'label']].reset_index(drop=True)\n",
    "# curated_dataset1 = read_csv('../input/daigt-proper-train-dataset/train_drcat_02.csv')[['text', 'label']].reset_index(drop=True)\n",
    "# curated_dataset2 = read_csv('../input/daigt-proper-train-dataset/train_drcat_03.csv')[['text', 'label']].reset_index(drop=True)\n",
    "# curated_dataset3 = read_csv('../input/daigt-proper-train-dataset/train_drcat_04.csv')[['text', 'label']].reset_index(drop=True)\n",
    "\n",
    "# curated_dataset4 = read_csv('../input/argugpt/machine-train.csv')[['text']].reset_index(drop=True).assign(label=1)\n",
    "# curated_dataset5 = read_csv('../input/argugpt/machine-test.csv')[['text']].reset_index(drop=True).assign(label=1)\n",
    "\n",
    "# curated_dataset6 = read_csv('../input/llm-generated-essays/ai_generated_train_essays.csv')[['text']].reset_index(drop=True).assign(label=1)\n",
    "# curated_dataset7 = read_csv('../input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv')[['text']].reset_index(drop=True).assign(label=1)\n",
    "\n",
    "# curated_dataset9 = read_csv('/kaggle/input/daigt-external-dataset/daigt_external_dataset.csv')[['text']].reset_index(drop=True).assign(label=1)\n",
    "# curated_dataset10 = read_csv('/kaggle/input/daigt-data-llama-70b-and-falcon180b/llama_70b_v1.csv')[['generated_text']].rename(columns={'generated_text' : 'text'}).reset_index(drop=True).assign(label=1)\n",
    "\n",
    "# curated_dataset11 = read_csv('/kaggle/input/daigt-data-llama-70b-and-falcon180b/falcon_180b_v1.csv')[['generated_text']].rename(columns={'generated_text' : 'text'}).reset_index(drop=True).assign(label=1)\n",
    "\n",
    "# curated_dataset12 = read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')[['text', 'label']].reset_index(drop=True)\n",
    "# curated_dataset13 = read_csv('/kaggle/input/hello-claude-1000-essays-from-anthropic/persuade15_claude_instant1.csv')[['essay_text']].rename(columns={'essay_text' : 'text'}).reset_index(drop=True).assign(label=1)\n",
    "# curated_dataset14 = read_csv('/kaggle/input/llm-generated-essay-using-palm-from-google-gen-ai/LLM_generated_essay_PaLM.csv')[['text', 'generated']].rename(columns={'generated' : 'label'})\n",
    "\n",
    "curated_dataset12 = read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')[['text', 'label']].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:12.349615Z",
     "iopub.status.busy": "2023-12-08T20:54:12.349160Z",
     "iopub.status.idle": "2023-12-08T20:54:12.392455Z",
     "shell.execute_reply": "2023-12-08T20:54:12.391144Z",
     "shell.execute_reply.started": "2023-12-08T20:54:12.349569Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "\n",
    "# train_dataset = concat([train_dataset, \n",
    "# #                         curated_dataset, \n",
    "# #                         curated_dataset1,\n",
    "# #                         curated_dataset2,\n",
    "#                         curated_dataset3,\n",
    "#                         curated_dataset4, \n",
    "#                         curated_dataset5, \n",
    "#                         curated_dataset6, \n",
    "#                         curated_dataset7, \n",
    "#                         curated_dataset9, \n",
    "#                         curated_dataset10, \n",
    "#                         curated_dataset11,\n",
    "#                         curated_dataset12, \n",
    "#                         curated_dataset13, \n",
    "#                         curated_dataset14])\n",
    "\n",
    "train_dataset = pd.concat([train_dataset, curated_dataset12])\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.text = train_dataset.text.str.replace('\\n', ' ')\n",
    "class_0_train = train_dataset[train_dataset['label'] == 0][:17500]\n",
    "class_0_test = train_dataset[train_dataset['label'] == 0][17500:]\n",
    "class_1 = train_dataset[train_dataset['label'] == 1]\n",
    "print(class_0_train)\n",
    "print(class_1)\n",
    "print(class_0_test)\n",
    "\n",
    "train_dataset = pd.concat([class_0_train, class_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:12.394808Z",
     "iopub.status.busy": "2023-12-08T20:54:12.394411Z",
     "iopub.status.idle": "2023-12-08T20:54:13.229883Z",
     "shell.execute_reply": "2023-12-08T20:54:13.228623Z",
     "shell.execute_reply.started": "2023-12-08T20:54:12.394775Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# split the dataset\n",
    "train_dataset.text = train_dataset.text.str.replace('\\n', ' ')\n",
    "class_0 = train_dataset[train_dataset['label'] == 0]\n",
    "class_1 = train_dataset[train_dataset['label'] == 1]\n",
    "\n",
    "# 确定两个类别的样本数量\n",
    "num_class_0 = len(class_0)\n",
    "num_class_1 = len(class_1)\n",
    "\n",
    "# 计算较小的样本数量\n",
    "min_num = min(num_class_0, num_class_1)\n",
    "\n",
    "# 对样本较多的类别进行随机抽样\n",
    "if num_class_0 > min_num:\n",
    "    class_0 = class_0.sample(n=min_num, random_state=42)  # random_state 确保结果的可复现性\n",
    "elif num_class_1 > min_num:\n",
    "    class_1 = class_1.sample(n=min_num, random_state=42)\n",
    "\n",
    "# 合并数据集\n",
    "balanced_train_dataset = pd.concat([class_0, class_1])\n",
    "\n",
    "# 如果需要，可以打乱数据集的顺序\n",
    "balanced_train_dataset = balanced_train_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:13.233946Z",
     "iopub.status.busy": "2023-12-08T20:54:13.232757Z",
     "iopub.status.idle": "2023-12-08T20:54:36.990338Z",
     "shell.execute_reply": "2023-12-08T20:54:36.989083Z",
     "shell.execute_reply.started": "2023-12-08T20:54:13.233895Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# 分词并计数单词个数\n",
    "word_counts = [len(re.findall(r'\\w+', text)) for text in balanced_train_dataset.text]\n",
    "\n",
    "# 绘制直方图\n",
    "plt.hist(word_counts, bins=50, edgecolor='black')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:36.992525Z",
     "iopub.status.busy": "2023-12-08T20:54:36.992163Z",
     "iopub.status.idle": "2023-12-08T20:54:36.998010Z",
     "shell.execute_reply": "2023-12-08T20:54:36.997097Z",
     "shell.execute_reply.started": "2023-12-08T20:54:36.992494Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_dataset = concat([train_dataset.query('label==0').sample(48475), train_dataset.query('label==1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:37.000111Z",
     "iopub.status.busy": "2023-12-08T20:54:36.999270Z",
     "iopub.status.idle": "2023-12-08T20:54:37.018929Z",
     "shell.execute_reply": "2023-12-08T20:54:37.017822Z",
     "shell.execute_reply.started": "2023-12-08T20:54:37.000077Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_train_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:37.020955Z",
     "iopub.status.busy": "2023-12-08T20:54:37.020579Z",
     "iopub.status.idle": "2023-12-08T20:54:37.033741Z",
     "shell.execute_reply": "2023-12-08T20:54:37.032392Z",
     "shell.execute_reply.started": "2023-12-08T20:54:37.020925Z"
    }
   },
   "outputs": [],
   "source": [
    "X = balanced_train_dataset.text\n",
    "y = balanced_train_dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:37.036203Z",
     "iopub.status.busy": "2023-12-08T20:54:37.035325Z",
     "iopub.status.idle": "2023-12-08T20:54:37.048257Z",
     "shell.execute_reply": "2023-12-08T20:54:37.047205Z",
     "shell.execute_reply.started": "2023-12-08T20:54:37.036171Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:54:37.050234Z",
     "iopub.status.busy": "2023-12-08T20:54:37.049761Z",
     "iopub.status.idle": "2023-12-08T20:55:06.575104Z",
     "shell.execute_reply": "2023-12-08T20:55:06.573579Z",
     "shell.execute_reply.started": "2023-12-08T20:54:37.050204Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n",
    "!mkdir -p /root/.cache/language_tool_python/\n",
    "!cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in /Users/johnsonl/miniconda3/lib/python3.11/site-packages (2023.10.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ---------\n",
      "archspec                0.2.1\n",
      "boltons                 23.0.0\n",
      "Brotli                  1.0.9\n",
      "certifi                 2023.7.22\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "conda                   23.10.0\n",
      "conda-content-trust     0.2.0\n",
      "conda-libmamba-solver   23.11.1\n",
      "conda-package-handling  2.2.0\n",
      "conda_package_streaming 0.9.0\n",
      "cryptography            41.0.3\n",
      "idna                    3.4\n",
      "joblib                  1.3.2\n",
      "jsonpatch               1.32\n",
      "jsonpointer             2.1\n",
      "libmambapy              1.5.3\n",
      "numpy                   1.26.2\n",
      "packaging               23.1\n",
      "pip                     23.3\n",
      "pluggy                  1.0.0\n",
      "pycosat                 0.6.6\n",
      "pycparser               2.21\n",
      "pyOpenSSL               23.2.0\n",
      "PySocks                 1.7.1\n",
      "regex                   2023.10.3\n",
      "requests                2.31.0\n",
      "ruamel.yaml             0.17.21\n",
      "scikit-learn            1.3.2\n",
      "scipy                   1.11.4\n",
      "setuptools              68.0.0\n",
      "threadpoolctl           3.2.0\n",
      "tqdm                    4.65.0\n",
      "truststore              0.8.0\n",
      "urllib3                 1.26.18\n",
      "wheel                   0.41.2\n",
      "zstandard               0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'regex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mregex\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression, SGDClassifier\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'regex'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import language_tool_python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "seed = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:55:08.177404Z",
     "iopub.status.busy": "2023-12-08T20:55:08.177013Z",
     "iopub.status.idle": "2023-12-08T20:55:10.786333Z",
     "shell.execute_reply": "2023-12-08T20:55:10.785297Z",
     "shell.execute_reply.started": "2023-12-08T20:55:08.177356Z"
    }
   },
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "def correct_sentence(sentence):\n",
    "    return tool.correct(sentence)\n",
    "def correct_df(df):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        df['text'] = list(executor.map(correct_sentence, df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T20:55:10.788181Z",
     "iopub.status.busy": "2023-12-08T20:55:10.787666Z",
     "iopub.status.idle": "2023-12-08T21:11:10.695533Z",
     "shell.execute_reply": "2023-12-08T21:11:10.694151Z",
     "shell.execute_reply.started": "2023-12-08T20:55:10.788137Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5),tokenizer=lambda x: re.findall(r'[^\\W]+', x), token_pattern=None, strip_accents='unicode')\n",
    "vectorizer = vectorizer.fit(X)\n",
    "X_train = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:11:10.700562Z",
     "iopub.status.busy": "2023-12-08T21:11:10.700153Z",
     "iopub.status.idle": "2023-12-08T21:11:36.162394Z",
     "shell.execute_reply": "2023-12-08T21:11:36.158829Z",
     "shell.execute_reply.started": "2023-12-08T21:11:10.700512Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(max_iter=8000, tol=3e-4, verbose=100, loss=\"modified_huber\")\n",
    "clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:11:36.165418Z",
     "iopub.status.busy": "2023-12-08T21:11:36.164633Z",
     "iopub.status.idle": "2023-12-08T21:11:37.438885Z",
     "shell.execute_reply": "2023-12-08T21:11:37.437641Z",
     "shell.execute_reply.started": "2023-12-08T21:11:36.165373Z"
    }
   },
   "outputs": [],
   "source": [
    "test1 = pd.read_csv('/kaggle/input/567testdata/Mistral7B_CME_v7_15_percent_corruption.csv')[['text', 'generated']].rename(columns={'generated' : 'label'})\n",
    "test2 = class_0_test\n",
    "\n",
    "test_dataset = pd.concat([test1, test2])\n",
    "import pandas as pd\n",
    "\n",
    "# split the dataset\n",
    "test_dataset.text = test_dataset.text.str.replace('\\n', ' ')\n",
    "class_0 = test_dataset[test_dataset['label'] == 0]\n",
    "class_1 = test_dataset[test_dataset['label'] == 1]\n",
    "\n",
    "# 确定两个类别的样本数量\n",
    "num_class_0 = len(class_0)\n",
    "num_class_1 = len(class_1)\n",
    "\n",
    "# 计算较小的样本数量\n",
    "min_num = min(num_class_0, num_class_1)\n",
    "\n",
    "# 对样本较多的类别进行随机抽样\n",
    "if num_class_0 > min_num:\n",
    "    class_0 = class_0.sample(n=5000, random_state=42)  # random_state 确保结果的可复现性\n",
    "elif num_class_1 > min_num:\n",
    "    class_1 = class_1.sample(n=min_num, random_state=42)\n",
    "\n",
    "# 合并数据集\n",
    "balanced_test_dataset = pd.concat([class_0, class_1])\n",
    "\n",
    "# 如果需要，可以打乱数据集的顺序\n",
    "balanced_test_dataset = balanced_test_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:11:37.440790Z",
     "iopub.status.busy": "2023-12-08T21:11:37.440384Z",
     "iopub.status.idle": "2023-12-08T21:12:12.924487Z",
     "shell.execute_reply": "2023-12-08T21:12:12.923330Z",
     "shell.execute_reply.started": "2023-12-08T21:11:37.440757Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(balanced_test_dataset['text'])\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:12:12.926337Z",
     "iopub.status.busy": "2023-12-08T21:12:12.926011Z",
     "iopub.status.idle": "2023-12-08T21:12:13.377132Z",
     "shell.execute_reply": "2023-12-08T21:12:13.375649Z",
     "shell.execute_reply.started": "2023-12-08T21:12:12.926309Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score, f1_score\n",
    "\n",
    "# 随机生成二元分类的真实标签（0或1）\n",
    "# y_true = test['label']\n",
    "y_test = balanced_test_dataset['label']\n",
    "pred = clf.predict(X_test)\n",
    "plt.hist(y_pred_prob, bins=10, color='#fb852d', alpha=0.7, rwidth=0.85, edgecolor='black')\n",
    "plt.title('Predict Probalbility Distribution')\n",
    "plt.xlabel('Probalbility')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "# 计算AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test, y_pred_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:12:13.378932Z",
     "iopub.status.busy": "2023-12-08T21:12:13.378580Z",
     "iopub.status.idle": "2023-12-08T21:12:13.384611Z",
     "shell.execute_reply": "2023-12-08T21:12:13.383306Z",
     "shell.execute_reply.started": "2023-12-08T21:12:13.378902Z"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# word_counts_test = [len(re.findall(r'\\w+', text)) for text in X]\n",
    "\n",
    "# # 绘制直方图\n",
    "# plt.hist(word_counts_test, bins=50, edgecolor='black')\n",
    "# plt.title('Word Count Distribution')\n",
    "# plt.xlabel('Number of Words')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:12:13.386715Z",
     "iopub.status.busy": "2023-12-08T21:12:13.386293Z",
     "iopub.status.idle": "2023-12-08T21:12:13.401903Z",
     "shell.execute_reply": "2023-12-08T21:12:13.400733Z",
     "shell.execute_reply.started": "2023-12-08T21:12:13.386674Z"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Example training loss values\n",
    "# epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "# training_loss = [0.135197, 0.107281, 0.104895, 0.104033, 0.103648, 0.103322, 0.103147, 0.103043, 0.102923, 0.102820, 0.102758]\n",
    "\n",
    "# # Plotting the training loss graph\n",
    "# plt.plot(epochs, training_loss, marker='o', antialiased=True)\n",
    "# plt.title('Training Loss Over Epochs')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Average Loss')\n",
    "# plt.grid(True)\n",
    "# plt.figure(dpi=10000)  # Adjust the DPI as needed for high resolution\n",
    "# plt.show()\n",
    "# plt.savefig('training_loss_plot.png', format='png', dpi=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-08T21:12:13.404498Z",
     "iopub.status.busy": "2023-12-08T21:12:13.404027Z",
     "iopub.status.idle": "2023-12-08T21:12:13.713517Z",
     "shell.execute_reply": "2023-12-08T21:12:13.712268Z",
     "shell.execute_reply.started": "2023-12-08T21:12:13.404456Z"
    }
   },
   "outputs": [],
   "source": [
    "false_positives = sum((y_test[i] == 0) and (y_pred[i] == 1) for i in range(len(y_test)))\n",
    "true_positives = sum((y_test[i] == 1) and (y_pred[i] == 1) for i in range(len(y_test)))\n",
    "false_negatives = sum((y_test[i] == 1) and (y_pred[i] == 0) for i in range(len(y_test)))\n",
    "true_negatives = sum((y_test[i] == 0) and (y_pred[i] == 0) for i in range(len(y_test)))\n",
    "print(false_positives)\n",
    "print(true_positives)\n",
    "print(false_negatives)\n",
    "print(true_negatives)\n",
    "print(len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3936750,
     "sourceId": 6847931,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3945154,
     "sourceId": 6865136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3946973,
     "sourceId": 6867914,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3937441,
     "sourceId": 6868189,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3955358,
     "sourceId": 6888403,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3942644,
     "sourceId": 6890527,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3973977,
     "sourceId": 6920799,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3961875,
     "sourceId": 6971638,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3937250,
     "sourceId": 7017419,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3944051,
     "sourceId": 7060310,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4123812,
     "sourceId": 7149898,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 1900,
     "sourceId": 2623,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
